#!/usr/bin/env python3
"""
CPU æ¨¡å¼é¢„æµ‹æµ‹è¯•å®¢æˆ·ç«¯ - 400â†’120 é…ç½®ï¼ˆå¯¹æ ‡åŽŸå§‹ exampleï¼‰

å®Œå…¨å¯¹åº”åŽŸå§‹ prediction_example.py çš„é…ç½®ï¼š
- è¾“å…¥é•¿åº¦: 400 ç‚¹
- é¢„æµ‹é•¿åº¦: 120 ç‚¹
- é‡‡æ ·æ¬¡æ•°: 1
"""

import json
import time
from datetime import datetime, timedelta
from typing import Dict, Any

import requests
import pandas as pd
import numpy as np


class KronosCPUTest400:
    """Kronos CPU æµ‹è¯•å®¢æˆ·ç«¯ - 400â†’120 é…ç½®"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.session = requests.Session()
        
    def check_health(self) -> Dict[str, Any]:
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        print("=" * 70)
        print("1. æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€")
        print("=" * 70)
        
        try:
            response = self.session.get(f"{self.base_url}/v1/healthz", timeout=5)
            response.raise_for_status()
            result = response.json()
            print(f"âœ“ æœåŠ¡å¥åº·: {result}")
            return result
        except Exception as e:
            print(f"âœ— å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            raise
    
    def check_ready(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ¨¡åž‹å°±ç»ªçŠ¶æ€"""
        print("\n" + "=" * 70)
        print("2. æ£€æŸ¥æ¨¡åž‹å°±ç»ªçŠ¶æ€")
        print("=" * 70)
        
        try:
            response = self.session.get(f"{self.base_url}/v1/readyz", timeout=5)
            response.raise_for_status()
            result = response.json()
            
            print(f"çŠ¶æ€: {result['status']}")
            print(f"æ¨¡åž‹å·²åŠ è½½: {result['model_loaded']}")
            print(f"è®¾å¤‡: {result.get('device', 'N/A')}")
            
            if result.get('device_warning'):
                print(f"âš  è®¾å¤‡è­¦å‘Š: {result['device_warning']}")
            
            if not result['model_loaded']:
                print("âœ— æ¨¡åž‹æœªåŠ è½½ï¼Œè¯·ç­‰å¾…...")
                return result
            
            print("âœ“ æ¨¡åž‹å°±ç»ª")
            return result
        except Exception as e:
            print(f"âœ— å°±ç»ªæ£€æŸ¥å¤±è´¥: {e}")
            raise
    
    def generate_test_data(self, length: int = 400) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ•°æ® - 400 ç‚¹åŽ†å²æ•°æ®"""
        print("\n" + "=" * 70)
        print("3. ç”Ÿæˆæµ‹è¯•æ•°æ®")
        print("=" * 70)
        
        # ç”Ÿæˆæ¨¡æ‹Ÿçš„ OHLCV æ•°æ®
        np.random.seed(42)
        base_price = 100.0
        
        # éšæœºæ¸¸èµ°ç”Ÿæˆä»·æ ¼
        returns = np.random.randn(length) * 0.02
        prices = base_price * np.exp(np.cumsum(returns))
        
        # ç”Ÿæˆ OHLCV
        candles = []
        timestamps = []
        
        start_time = datetime(2024, 1, 1, 9, 30)
        
        for i in range(length):
            close = prices[i]
            
            # ç”Ÿæˆ high å’Œ lowï¼ˆç¡®ä¿ç¬¦åˆé€»è¾‘ï¼‰
            high_offset = abs(np.random.randn() * 0.01)
            low_offset = abs(np.random.randn() * 0.01)
            
            # open åœ¨ low å’Œ high ä¹‹é—´
            open_price = close + (np.random.randn() * 0.005 * close)
            
            # ç¡®ä¿ high >= max(open, close) ä¸” low <= min(open, close)
            high = max(open_price, close) * (1 + high_offset)
            low = min(open_price, close) * (1 - low_offset)
            
            volume = abs(np.random.randn() * 1000000)
            
            candles.append({
                "open": float(open_price),
                "high": float(high),
                "low": float(low),
                "close": float(close),
                "volume": float(volume),
                "amount": float(volume * close)
            })
            
            timestamps.append((start_time + timedelta(minutes=i)).isoformat())
        
        print(f"âœ“ ç”Ÿæˆ {length} æ¡ K çº¿æ•°æ®ï¼ˆåŽ†å²è¾“å…¥ï¼‰")
        print(f"  æ—¶é—´èŒƒå›´: {timestamps[0]} åˆ° {timestamps[-1]}")
        print(f"  ä»·æ ¼èŒƒå›´: {min(prices):.2f} - {max(prices):.2f}")
        
        return {
            "candles": candles,
            "timestamps": timestamps
        }
    
    def predict_long_sequence(
        self,
        candles: list,
        timestamps: list,
        pred_len: int = 120,
        temperature: float = 1.0,
        sample_count: int = 1
    ) -> Dict[str, Any]:
        """æ‰§è¡Œé•¿åºåˆ—é¢„æµ‹ï¼ˆ400â†’120ï¼‰å¹¶ç»Ÿè®¡æ—¶é—´"""
        print("\n" + "=" * 70)
        print("4. æ‰§è¡Œ CPU é•¿åºåˆ—é¢„æµ‹ (400 â†’ 120)")
        print("=" * 70)
        
        # ç”Ÿæˆæœªæ¥æ—¶é—´æˆ³
        last_time = datetime.fromisoformat(timestamps[-1])
        prediction_timestamps = [
            (last_time + timedelta(minutes=i+1)).isoformat()
            for i in range(pred_len)
        ]
        
        # æž„å»ºè¯·æ±‚
        request_data = {
            "series_id": "test_cpu_400_120",
            "candles": candles,
            "timestamps": timestamps,
            "prediction_timestamps": prediction_timestamps,
            "overrides": {
                "pred_len": pred_len,
                "temperature": temperature,
                "top_k": 0,
                "top_p": 0.9,
                "sample_count": sample_count
            }
        }
        
        print(f"è¯·æ±‚å‚æ•°:")
        print(f"  è¾“å…¥æ•°æ®ç‚¹: {len(candles)}")
        print(f"  é¢„æµ‹é•¿åº¦: {pred_len}")
        print(f"  Temperature: {temperature}")
        print(f"  é‡‡æ ·æ¬¡æ•°: {sample_count}")
        print(f"\nâš ï¸  è­¦å‘Š: é•¿åºåˆ—é¢„æµ‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆé¢„ä¼° 20-30 ç§’ï¼‰")
        print(f"å¼€å§‹é¢„æµ‹...")
        
        # å¼€å§‹è®¡æ—¶
        start_time = time.time()
        
        try:
            response = self.session.post(
                f"{self.base_url}/v1/predict/single",
                json=request_data,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            # ç»“æŸè®¡æ—¶
            end_time = time.time()
            elapsed_time = end_time - start_time
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code != 200:
                print(f"\nâœ— HTTP {response.status_code} é”™è¯¯")
                print(f"å“åº”å†…å®¹: {response.text[:500]}")
            
            response.raise_for_status()
            result = response.json()
            
            print(f"\nâœ“ é¢„æµ‹å®Œæˆ!")
            print(f"\n{'=' * 70}")
            print(f"â±ï¸  é¢„æµ‹æ—¶é—´ç»Ÿè®¡")
            print(f"{'=' * 70}")
            print(f"æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
            print(f"å¹³å‡æ¯ä¸ªé¢„æµ‹ç‚¹: {elapsed_time / pred_len:.3f} ç§’")
            print(f"åžåé‡: {pred_len / elapsed_time:.2f} ç‚¹/ç§’")
            
            # æ˜¾ç¤ºé¢„æµ‹ç»“æžœæ ·ä¾‹
            if result.get('prediction'):
                predictions = result['prediction']
                print(f"\né¢„æµ‹ç»“æžœæ ·æœ¬ï¼ˆå‰3ä¸ªç‚¹ï¼‰:")
                for i, pred in enumerate(predictions[:3], 1):
                    print(f"  {i}. æ—¶é—´: {pred['timestamp']}")
                    print(f"     OHLC: O={pred['open']:.2f}, H={pred['high']:.2f}, "
                          f"L={pred['low']:.2f}, C={pred['close']:.2f}")
                
                print(f"\né¢„æµ‹ç»“æžœæ ·æœ¬ï¼ˆæœ€åŽ3ä¸ªç‚¹ï¼‰:")
                for i, pred in enumerate(predictions[-3:], len(predictions)-2):
                    print(f"  {i}. æ—¶é—´: {pred['timestamp']}")
                    print(f"     OHLC: O={pred['open']:.2f}, H={pred['high']:.2f}, "
                          f"L={pred['low']:.2f}, C={pred['close']:.2f}")
            
            # ä¸ŽåŽŸå§‹ example å¯¹æ¯”
            print(f"\n{'=' * 70}")
            print(f"ðŸ“Š ä¸ŽåŽŸå§‹ prediction_example.py å¯¹æ¯”")
            print(f"{'=' * 70}")
            print(f"åŽŸå§‹ example (ç›´æŽ¥è°ƒç”¨æ¨¡åž‹):")
            print(f"  é…ç½®: 400 è¾“å…¥ â†’ 120 é¢„æµ‹")
            print(f"  è®¾å¤‡: CPU")
            print(f"  è€—æ—¶: 25.87 ç§’")
            print(f"  åžå: 4.64 ç‚¹/ç§’")
            print(f"\nå½“å‰æµ‹è¯• (FastAPI æœåŠ¡):")
            print(f"  é…ç½®: {len(candles)} è¾“å…¥ â†’ {pred_len} é¢„æµ‹")
            print(f"  è®¾å¤‡: CPU")
            print(f"  è€—æ—¶: {elapsed_time:.2f} ç§’")
            print(f"  åžå: {pred_len / elapsed_time:.2f} ç‚¹/ç§’")
            
            # è®¡ç®—å·®å¼‚
            original_time = 25.87
            speedup = original_time / elapsed_time if elapsed_time > 0 else 0
            overhead = ((elapsed_time - original_time) / original_time * 100) if original_time > 0 else 0
            
            print(f"\næ€§èƒ½å¯¹æ¯”:")
            if speedup > 1:
                print(f"  âœ“ FastAPI æ›´å¿«: {speedup:.2f}x")
            elif speedup < 1:
                print(f"  âš  FastAPI è¾ƒæ…¢: {1/speedup:.2f}x")
                print(f"  âš  å¼€é”€: {overhead:.1f}%")
                print(f"     ï¼ˆåŒ…å«ç½‘ç»œè¯·æ±‚ã€åºåˆ—åŒ–ç­‰é¢å¤–å¼€é”€ï¼‰")
            else:
                print(f"  â‰ˆ æ€§èƒ½ç›¸å½“")
            
            return {
                "elapsed_time": elapsed_time,
                "pred_len": pred_len,
                "time_per_point": elapsed_time / pred_len,
                "throughput": pred_len / elapsed_time,
                "result": result
            }
            
        except requests.exceptions.Timeout:
            end_time = time.time()
            elapsed_time = end_time - start_time
            print(f"\nâœ— è¯·æ±‚è¶…æ—¶ (è€—æ—¶ {elapsed_time:.2f} ç§’)")
            print(f"æç¤º: é•¿åºåˆ—é¢„æµ‹å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼Œè¯·è€ƒè™‘:")
            print(f"  1. å¢žåŠ è¶…æ—¶æ—¶é—´")
            print(f"  2. å‡å°‘é¢„æµ‹é•¿åº¦")
            print(f"  3. ä½¿ç”¨ GPU åŠ é€Ÿ")
            raise
        except Exception as e:
            end_time = time.time()
            elapsed_time = end_time - start_time
            print(f"\nâœ— é¢„æµ‹å¤±è´¥ (è€—æ—¶ {elapsed_time:.2f} ç§’): {e}")
            raise


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("Kronos CPU æ¨¡å¼é¢„æµ‹æµ‹è¯• - 400â†’120 é…ç½®")
    print("å¯¹æ ‡åŽŸå§‹ prediction_example.py")
    print("=" * 70)
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = KronosCPUTest400(base_url="http://localhost:8000")
    
    try:
        # 1. å¥åº·æ£€æŸ¥
        client.check_health()
        
        # 2. å°±ç»ªæ£€æŸ¥
        ready_status = client.check_ready()
        
        if not ready_status.get('model_loaded'):
            print("\nè¯·ç­‰å¾…æ¨¡åž‹åŠ è½½å®ŒæˆåŽé‡è¯•")
            return
        
        # 3. ç”Ÿæˆæµ‹è¯•æ•°æ® (400 ç‚¹)
        test_data = client.generate_test_data(length=400)
        
        # 4. é•¿åºåˆ—é¢„æµ‹æµ‹è¯• (400 â†’ 120)
        print("\n" + "âš " * 35)
        print("æ³¨æ„: æ­¤æµ‹è¯•å°†é¢„æµ‹ 120 ä¸ªç‚¹ï¼Œé¢„è®¡éœ€è¦ 20-30 ç§’")
        print("è¯·è€å¿ƒç­‰å¾…...")
        print("âš " * 35)
        
        result = client.predict_long_sequence(
            candles=test_data["candles"],
            timestamps=test_data["timestamps"],
            pred_len=120,
            temperature=1.0,
            sample_count=1
        )
        
        print("\n" + "=" * 70)
        print("âœ“ æµ‹è¯•å®Œæˆ")
        print("=" * 70)
        
        # ä¿å­˜ç»“æžœ
        output_file = "/data/ws/kronos/logs/test_400_120_result.json"
        with open(output_file, 'w') as f:
            json.dump({
                "test_config": {
                    "input_length": 400,
                    "pred_length": 120,
                    "sample_count": 1,
                    "device": "cpu"
                },
                "performance": {
                    "elapsed_time": result["elapsed_time"],
                    "time_per_point": result["time_per_point"],
                    "throughput": result["throughput"]
                },
                "timestamp": datetime.now().isoformat()
            }, f, indent=2)
        print(f"\nç»“æžœå·²ä¿å­˜åˆ°: {output_file}")
        
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\n\nâœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
