#!/usr/bin/env python3
"""
GPU æ¨¡å¼é¢„æµ‹æµ‹è¯•å®¢æˆ·ç«¯ - 400â†’120 é…ç½®

å¯¹æ¯” CPU vs GPU æ€§èƒ½
"""

import json
import time
from datetime import datetime, timedelta
from typing import Dict, Any

import requests
import numpy as np


class KronosGPUTest400:
    """Kronos GPU æµ‹è¯•å®¢æˆ·ç«¯ - 400â†’120 é…ç½®"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.session = requests.Session()
        
    def check_ready(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ¨¡å‹å°±ç»ªçŠ¶æ€"""
        print("=" * 70)
        print("æ£€æŸ¥ GPU æ¨¡å‹å°±ç»ªçŠ¶æ€")
        print("=" * 70)
        
        response = self.session.get(f"{self.base_url}/v1/readyz", timeout=5)
        response.raise_for_status()
        result = response.json()
        
        print(f"çŠ¶æ€: {result['status']}")
        print(f"æ¨¡å‹å·²åŠ è½½: {result['model_loaded']}")
        print(f"è®¾å¤‡: {result.get('device', 'N/A')}")
        
        if result.get('device_warning'):
            print(f"âš  è®¾å¤‡è­¦å‘Š: {result['device_warning']}")
        
        if not result['model_loaded']:
            print("âœ— æ¨¡å‹æœªåŠ è½½ï¼Œè¯·ç­‰å¾…...")
            return result
        
        if 'cuda' not in result.get('device', '').lower():
            print(f"âš  è­¦å‘Š: æœŸæœ› GPU è®¾å¤‡ï¼Œä½†å¾—åˆ°: {result.get('device')}")
        else:
            print("âœ“ GPU æ¨¡å‹å°±ç»ª")
        
        return result
    
    def generate_test_data(self, length: int = 400) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ•°æ® - 400 ç‚¹å†å²æ•°æ®"""
        print("\n" + "=" * 70)
        print("ç”Ÿæˆæµ‹è¯•æ•°æ®")
        print("=" * 70)
        
        np.random.seed(42)
        base_price = 100.0
        
        returns = np.random.randn(length) * 0.02
        prices = base_price * np.exp(np.cumsum(returns))
        
        candles = []
        timestamps = []
        
        start_time = datetime(2024, 1, 1, 9, 30)
        
        for i in range(length):
            close = prices[i]
            
            high_offset = abs(np.random.randn() * 0.01)
            low_offset = abs(np.random.randn() * 0.01)
            
            open_price = close + (np.random.randn() * 0.005 * close)
            
            high = max(open_price, close) * (1 + high_offset)
            low = min(open_price, close) * (1 - low_offset)
            
            volume = abs(np.random.randn() * 1000000)
            
            candles.append({
                "open": float(open_price),
                "high": float(high),
                "low": float(low),
                "close": float(close),
                "volume": float(volume),
                "amount": float(volume * close)
            })
            
            timestamps.append((start_time + timedelta(minutes=i)).isoformat())
        
        print(f"âœ“ ç”Ÿæˆ {length} æ¡ K çº¿æ•°æ®ï¼ˆå†å²è¾“å…¥ï¼‰")
        
        return {
            "candles": candles,
            "timestamps": timestamps
        }
    
    def predict_gpu(
        self,
        candles: list,
        timestamps: list,
        pred_len: int = 120
    ) -> Dict[str, Any]:
        """æ‰§è¡Œ GPU é¢„æµ‹å¹¶ç»Ÿè®¡æ—¶é—´"""
        print("\n" + "=" * 70)
        print(f"æ‰§è¡Œ GPU é¢„æµ‹ (400 â†’ {pred_len})")
        print("=" * 70)
        
        last_time = datetime.fromisoformat(timestamps[-1])
        prediction_timestamps = [
            (last_time + timedelta(minutes=i+1)).isoformat()
            for i in range(pred_len)
        ]
        
        request_data = {
            "series_id": "test_gpu_400_120",
            "candles": candles,
            "timestamps": timestamps,
            "prediction_timestamps": prediction_timestamps,
            "overrides": {
                "pred_len": pred_len,
                "temperature": 1.0,
                "top_k": 0,
                "top_p": 0.9,
                "sample_count": 1
            }
        }
        
        print(f"è¯·æ±‚å‚æ•°:")
        print(f"  è¾“å…¥æ•°æ®ç‚¹: {len(candles)}")
        print(f"  é¢„æµ‹é•¿åº¦: {pred_len}")
        print(f"  è®¾å¤‡: GPU (Tesla M40)")
        print(f"\nå¼€å§‹é¢„æµ‹...")
        
        start_time = time.time()
        
        response = self.session.post(
            f"{self.base_url}/v1/predict/single",
            json=request_data,
            timeout=120
        )
        
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        if response.status_code != 200:
            print(f"\nâœ— HTTP {response.status_code} é”™è¯¯")
            print(f"å“åº”: {response.text[:500]}")
        
        response.raise_for_status()
        result = response.json()
        
        print(f"\nâœ“ GPU é¢„æµ‹å®Œæˆ!")
        print(f"\n{'=' * 70}")
        print(f"â±ï¸  GPU é¢„æµ‹æ—¶é—´ç»Ÿè®¡")
        print(f"{'=' * 70}")
        print(f"æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        print(f"å¹³å‡æ¯ä¸ªé¢„æµ‹ç‚¹: {elapsed_time / pred_len:.3f} ç§’")
        print(f"ååé‡: {pred_len / elapsed_time:.2f} ç‚¹/ç§’")
        
        return {
            "elapsed_time": elapsed_time,
            "pred_len": pred_len,
            "time_per_point": elapsed_time / pred_len,
            "throughput": pred_len / elapsed_time,
            "result": result
        }


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("Kronos GPU æ¨¡å¼é¢„æµ‹æµ‹è¯• - 400â†’120 é…ç½®")
    print("=" * 70)
    
    client = KronosGPUTest400(base_url="http://localhost:8000")
    
    try:
        # 1. å°±ç»ªæ£€æŸ¥
        ready_status = client.check_ready()
        
        if not ready_status.get('model_loaded'):
            print("\nè¯·ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆåé‡è¯•")
            return
        
        # 2. ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_data = client.generate_test_data(length=400)
        
        # 3. GPU é¢„æµ‹
        gpu_result = client.predict_gpu(
            candles=test_data["candles"],
            timestamps=test_data["timestamps"],
            pred_len=120
        )
        
        # 4. æ€§èƒ½å¯¹æ¯”
        print("\n" + "=" * 70)
        print("ğŸ“Š CPU vs GPU æ€§èƒ½å¯¹æ¯”")
        print("=" * 70)
        
        cpu_time = 32.86  # CPU æµ‹è¯•ç»“æœ
        gpu_time = gpu_result["elapsed_time"]
        speedup = cpu_time / gpu_time
        
        print(f"\nCPU (FastAPI):")
        print(f"  æ€»è€—æ—¶: {cpu_time:.2f} ç§’")
        print(f"  ååé‡: {120/cpu_time:.2f} ç‚¹/ç§’")
        
        print(f"\nGPU (FastAPI):")
        print(f"  æ€»è€—æ—¶: {gpu_time:.2f} ç§’")
        print(f"  ååé‡: {gpu_result['throughput']:.2f} ç‚¹/ç§’")
        
        print(f"\nGPU åŠ é€Ÿæ¯”: {speedup:.2f}x")
        
        if speedup > 5:
            print("  âœ“ æ˜¾è‘—åŠ é€Ÿï¼")
        elif speedup > 2:
            print("  âœ“ æ˜æ˜¾åŠ é€Ÿ")
        else:
            print("  âš  åŠ é€Ÿæœ‰é™")
        
        # ä¿å­˜ç»“æœ
        output_file = "/data/ws/kronos/logs/test_gpu_400_120_result.json"
        with open(output_file, 'w') as f:
            json.dump({
                "test_config": {
                    "input_length": 400,
                    "pred_length": 120,
                    "device": "cuda:0 (Tesla M40)"
                },
                "performance": {
                    "gpu_time": gpu_time,
                    "cpu_time": cpu_time,
                    "speedup": speedup,
                    "throughput": gpu_result["throughput"]
                },
                "timestamp": datetime.now().isoformat()
            }, f, indent=2)
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        print("\n" + "=" * 70)
        print("âœ“ GPU æµ‹è¯•å®Œæˆ")
        print("=" * 70)
        
    except Exception as e:
        print(f"\n\nâœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
